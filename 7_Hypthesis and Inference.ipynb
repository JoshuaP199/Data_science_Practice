{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.1 64-bit",
   "display_name": "Python 3.6.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "d91e8cf5da37e178649d67f5172d212fc824bfda2fb358203aaa45c4578e1c5e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPOTHESIS AND INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example: Flipping a Coin\n",
    "#p -> probabilty of the coin landing heads\n",
    "#n -> number of flips\n",
    "#X -> number of heads\n",
    "#mu -> mean\n",
    "#sigma -> standard deviation\n",
    "\n",
    "from typing import Tuple\n",
    "import math\n",
    "\n",
    "def normal_approximation_to_binomial(n: int, p: float) -> Tuple[float, float]:\n",
    "    \"\"\"Returns mu and sigma corresponding to a Binomial(n,p)\"\"\"\n",
    "    mu = p * n \n",
    "    sigma = math.sqrt(p * (1-p) * n)\n",
    "    return mu, sigma\n",
    "\n",
    "#print(normal_approximation_to_binomial(1000, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from scratch.probability import normal_cdf\n",
    "\n",
    "#The normal cdf _is_ the probabilty the variable is below a threshold\n",
    "normal_probability_below = normal_cdf\n",
    "\n",
    "#It's above the threshold if it's not below the threshold\n",
    "def normal_probability_above(lo: float, mu: float = 0, sigma: float = 1) -> float:\n",
    "    \"\"\"The probability that an N(mu, sigma) is greater than lo.\"\"\"\n",
    "    return 1 - normal_cdf(lo, mu, sigma)\n",
    "\n",
    "#It's between if it's less than hi, but not less than lo\n",
    "def normal_probability_between(lo: float, hi: float, mu: float = 0, sigma=1) -> float:\n",
    "    \"\"\"The probability that an N(mu, sigma) is between lo and hi\"\"\"\n",
    "    return normal_cdf(hi, mu, sigma) - normal_cdf(lo, mu, sigma)\n",
    "\n",
    "#It's outside if it's not between\n",
    "def normal_probability_outside(lo:float, hi: float, mu: float=0, sigma: float=1) -> float:\n",
    "    \"\"\"The probability that an N(mu, sigma) is not between lo and hi.\"\"\"\n",
    "    return 1 - normal_probability_between(lo, hi, mu, sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scratch.probability import inverse_normal_cdf\n",
    "from typing import Tuple\n",
    "\n",
    "def normal_upper_bound(probability: float, mu: float = 0, sigma: float = 1) -> float:\n",
    "    \"\"\"Returns the z for which P(Z <= z) = probability\"\"\"\n",
    "    return inverse_normal_cdf(probability, mu, sigma)\n",
    "\n",
    "def normal_lower_bound(probability: float, mu: float=0, sigma: float = 1) -> float:\n",
    "    \"\"\"Returns the z for which P(Z >= z) = probability\"\"\"\n",
    "    return inverse_normal_cdf(1- probability, mu, sigma)\n",
    "\n",
    "def normal_two_sided_bounds(probability: float, mu: float = 0, sigma: float=1) -> Tuple[float,float]:\n",
    "    \"\"\"Returns the symmetric (about the mean) bounds that contain the specified probability\"\"\"\n",
    "    tail_probability = (1-probability) / 2\n",
    "\n",
    "    #upper bound should have tail_probability above it\n",
    "    upper_bound = normal_lower_bound(tail_probability, mu, sigma)\n",
    "\n",
    "    #lower bound should have tail_probability below it\n",
    "    lower_bound = normal_upper_bound(tail_probability, mu, sigma)\n",
    "\n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRY TO UNDERSTAND MORE, PAGE 85-86\n",
    "mu_0, sigma_0 = normal_approximation_to_binomial(1000, 0.5)\n",
    "\n",
    "#Significance - type 1 error('false positive') are we willing to make, often 1% or 5%, we chose 5%\n",
    "lower_bound, upper_bound = normal_two_sided_bounds(0.95, mu_0, sigma_0)\n",
    "#(469, 531) \n",
    "\n",
    "#Power of a test - the probability of not making a type 2 error ('False negative')\n",
    "#set p = 0.55, so its slightly biased toward heads\n",
    "\n",
    "#95% bounds based on assumption p is 0.5\n",
    "lo, hi = normal_two_sided_bounds(0.95, mu_0, sigma_0)\n",
    "\n",
    "#actual mu and sigma based on p = 0.55\n",
    "mu_1, sigma_1 = normal_approximation_to_binomial(1000,0.55)\n",
    "\n",
    "#a type 2 error means we fail to reject the null hypothesis\n",
    "#which will happen when X is still in our original interval\n",
    "type_2_probability = normal_probability_between(lo, hi, mu_1, sigma_1)\n",
    "power = 1- type_2_probability #0.887\n",
    "\n",
    "hi = normal_upper_bound(0.95, mu_0, sigma_0)\n",
    "#is 526 (< 531, since we need more probability in the upper tail)\n",
    "\n",
    "type_2_probability = normal_probability_below(hi, mu_1, sigma_1)\n",
    "power = 1 - type_2_probability #0.936"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.06207721579598857"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#p-Values\n",
    "\n",
    "def two_sided_p_value(x: float, mu: float = 0, sigma:float=1) -> float:\n",
    "    \"\"\"How likely are we to see a value at least as extreme as x (in either direction) if our values are from an N(mu, sigma)?\"\"\"\n",
    "    if x >= mu:\n",
    "        #x is greater than the mean, so the tail is everything greater than x\n",
    "        return 2*normal_probability_above(x, mu, sigma)\n",
    "    else:\n",
    "        #x is less than the mean, so the tail is everything less than x\n",
    "        return 2*normal_probability_below(x,mu, sigma)\n",
    "\n",
    "two_sided_p_value(529.5, mu_0,sigma_0) #0.062\n",
    "#used 529.5 rather than 530 b/c of continuity correction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulation to convince me that this is a sensible estimate\n",
    "import random\n",
    "\n",
    "extreme_value_count = 0\n",
    "for _ in range(1000):\n",
    "    num_heads = sum(1 if random.random() < 0.5 else 0   #Count # of heads\n",
    "     for _ in range(1000))                              #in 1000 flips\n",
    "    if num_heads >= 530 or num_heads <= 470:            #and count how often\n",
    "        extreme_value_count += 1                        #the # is 'extreme'\n",
    "\n",
    "#p-value was 0.062 => ~62 extreme values out of 1000\n",
    "assert 59 < extreme_value_count < 65, f\"{extreme_value_count}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.04686839508859242"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "two_sided_p_value(531.5, mu_0, sigma_0)  #0.0463\n",
    "\n",
    "upper_p_value = normal_probability_above\n",
    "lower_p_value = normal_probability_below\n",
    "\n",
    "#for our one-sided test, if we saw 525 heads\n",
    "upper_p_value(524.5, mu_0,sigma_0) #0.061, so we wouldnt reject the null\n",
    "\n",
    "#if we saw 527 heads\n",
    "upper_p_value(526.5, mu_0,sigma_0) #0.047, so we would reject the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.4940490278129096, 0.5559509721870904)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "#Confidence Intervals\n",
    "\n",
    "#math.sqrt(p * (1-p) / 1000)\n",
    "\n",
    "p_hat = 525 / 1000\n",
    "mu = p_hat\n",
    "sigma = math.sqrt(p_hat * (1 - p_hat) / 1000) #0.0158\n",
    "\n",
    "normal_two_sided_bounds(0.95, mu, sigma) #[0.4940, 0.5560]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.5091095927295919, 0.5708904072704082)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "p_hat = 540 / 1000\n",
    "mu = p_hat\n",
    "sigma = math.sqrt(p_hat * (1 - p_hat) / 1000) #0.0158\n",
    "\n",
    "normal_two_sided_bounds(0.95, mu, sigma) #[0.5091, 0.5709]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#P-Hacking\n",
    "\n",
    "from typing import List\n",
    "\n",
    "def run_experiment() -> List[bool]:\n",
    "    \"\"\"Flips a fair coin 1000 times, True = heads, False = tails\"\"\"\n",
    "    return [random.random() < 0.5 for _ in range(1000)]\n",
    "\n",
    "def reject_fairness(experiment: List[bool]) -> bool:\n",
    "    \"\"\"Using the 5% significance levels\"\"\"\n",
    "    num_heads = len([flip for flip in experiment if flip])\n",
    "    return num_heads < 469 or num_heads > 531\n",
    "\n",
    "random.seed(0)\n",
    "experiments = [run_experiment() for _ in range(1000)]\n",
    "num_rejections = len([experiment for experiment in experiments if reject_fairness(experiment)])\n",
    "\n",
    "assert num_rejections == 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example: Running an A/B Test\n",
    "#Description: \n",
    "\"\"\"\n",
    "    Run an experiment by randomly showing site visitors one of the two advertisments and tracking how many people click on each one.\n",
    "    If the differences between the two are close then use statistical inference(what we are using)\n",
    "\"\"\"\n",
    "\n",
    "def estimated_parameters(N: int, n: int) -> Tuple[float, float]:\n",
    "    p = n / N\n",
    "    sigma = math.sqrt(p * (1-p) / N)\n",
    "    return p, sigma\n",
    "\n",
    "def a_b_test_statistic(N_A: int, n_A: int, N_B: int, n_B: int) -> float:\n",
    "    p_A, sigma_A = estimated_parameters(N_A, n_A)\n",
    "    p_B, sigma_B = estimated_parameters(N_B, n_B)\n",
    "    return (p_B - p_A) / math.sqrt(sigma_A ** 2 + sigma_B ** 2)\n",
    "\n",
    "#Ex: if a gets 200 clicks out of 1000 views and b gets 180 clicks out of 1000 views, the statistic equals\n",
    "    z = a_b_test_statistic(1000, 200, 1000, 180) #-1.14\n",
    "\n",
    "#the probability of seeing such a large difference if the means were actually equal\n",
    "    two_sided_p_value(z)\n",
    "#which is large enough that we can't conclude there's much of a difference\n",
    "\n",
    "#If b only got 150 clicks\n",
    "    z = a_b_test_statistic(1000, 200, 1000, 150) #-2.94\n",
    "    two_sided_p_value(z)    #0.003\n",
    "#which means there's only a 0.003 probability we'd see such a large difference if the ads were equally effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayesian Inference\n",
    "\n",
    "def B(alpha: float, beta: float) -> float:\n",
    "    \"\"\"A normalizing constant so that the total probability is 1\"\"\"\n",
    "    return math.gamma(alpha) * math.gamma(beta) / math.gamma(alpha + beta)\n",
    "\n",
    "def beta_pdf(x: float, alpha: float, beta: float) -> float:\n",
    "    if x <= 0 or x >= 1:\n",
    "        return 0\n",
    "    return x ** (alpha - 1) * (1-x) ** (beta - 1) / B(alpha, beta)\n",
    "\n",
    "#Generally speaking, this distribution centers arounds its weight at: alpha / (alpha + beta) and the larger the alpha and beta are, the \"tighter\" the distribution is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}